{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff68826-8805-4b04-8a6f-a6ab839d1259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import h5py\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "033d1351-61ea-481b-b57f-5d8b4872d815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966 4966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e1b98950894bd796c946d36d20652f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13990 13990\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2c34e14cf04926986fb270e9db3d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WITH_LABELS, WITHOUT_LABELS = True, False\n",
    "\n",
    "files = [\n",
    "    ('test', WITH_LABELS),\n",
    "    # ('train', WITHOUT_LABELS),\n",
    "    ('train_full_genuine', WITHOUT_LABELS),\n",
    "    # ('train_95_genuine', WITHOUT_LABELS),\n",
    "    # ('train_90_genuine', WITHOUT_LABELS),\n",
    "]\n",
    "\n",
    "fields = [\n",
    "    'snd_pos_x',\n",
    "    'snd_pos_y',\n",
    "    'snd_spd_x',\n",
    "    'snd_spd_y',\n",
    "    'snd_acl_x',\n",
    "    'snd_acl_y',\n",
    "    'snd_hed_x',\n",
    "    'snd_hed_y',\n",
    "    'rcv_pos_x',\n",
    "    'rcv_pos_y',\n",
    "    'rcv_spd_x',\n",
    "    'rcv_spd_y',\n",
    "    'rcv_acl_x',\n",
    "    'rcv_acl_y',\n",
    "    'rcv_hed_x',\n",
    "    'rcv_hed_y',\n",
    "    #'delta_time',\n",
    "]\n",
    "\n",
    "def normalize3(a, min_a, max_a):\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001)\n",
    "\n",
    "window_size = 20\n",
    "stride = 10\n",
    "V = pd.read_feather(f'out_veremi/veremi-mixall.feather')\n",
    "\n",
    "datasets = V.groupby('dataset_id').attack_type.unique()\n",
    "dataset_to_main_attack = {\n",
    "    key: int(attacks.max()) if len(attacks) == 2 else 0\n",
    "    for key, attacks in zip(datasets.index, datasets)\n",
    "}\n",
    "\n",
    "all_seqs = V[fields]\n",
    "min_a = all_seqs.min(axis=0).to_numpy()\n",
    "max_a = all_seqs.max(axis=0).to_numpy()\n",
    "del all_seqs\n",
    "\n",
    "for file, save_labels in files:\n",
    "    # stride = stride if file != 'test' else 1\n",
    "    df = pd.read_feather(f'out_veremi/{file}-mixall.feather')\n",
    "    \n",
    "    # group by sender and receiver\n",
    "    # grouped = df.groupby(['dataset_id', 'sender', 'receiver', 'attack_type'])\n",
    "    grouped = df.groupby(['dataset_id', 'sender', 'attack_type'])\n",
    "    grouped_size = grouped.size().sort_values(ascending=False)\n",
    "    sorted_order = grouped_size.index\n",
    "    \n",
    "    diff = (grouped_size - window_size) // stride\n",
    "    num_windows_all = np.where(diff >= 0, diff + 1, 0)\n",
    "    del diff\n",
    "\n",
    "    count_seqs = num_windows_all.sum()\n",
    "    sequences = np.empty((window_size, count_seqs, len(fields)), dtype=np.float32)\n",
    "    #sequences = np.memmap('sequences.memmap', dtype='float32', mode='w+', shape=(window_size, count_seqs, len(fields)))\n",
    "    if save_labels:\n",
    "        labels = np.empty((count_seqs, 3), dtype=np.uint32)\n",
    "    seq_idx = 0\n",
    "    print(len(sorted_order), len(num_windows_all))\n",
    "    for group_id, k, num_windows in tqdm(zip(range(len(sorted_order)), sorted_order, num_windows_all), total=len(num_windows_all)):\n",
    "        if num_windows <= 0:\n",
    "            continue\n",
    "        t = grouped.get_group(k)\n",
    "        t = t.sort_values(['bsm_rcv_time', 'receiver'])\n",
    "        attack_type = k[-1]\n",
    "        \n",
    "        array = t[fields].to_numpy()\n",
    "        for i in range(num_windows):\n",
    "            start_idx = i * stride\n",
    "            end_idx = start_idx + window_size\n",
    "            window = array[start_idx : end_idx]\n",
    "            sequences[:, seq_idx] = normalize3(window, min_a=min_a, max_a=max_a)\n",
    "            if save_labels:\n",
    "                labels[seq_idx] = (attack_type, dataset_to_main_attack[k[0]], group_id) \n",
    "            seq_idx += 1\n",
    "\n",
    "        # Comentado porque será truncado, mas descomentar caso não queira truncar\n",
    "        # final_window_size = len(t) % window_size\n",
    "        # if final_window_size > 0:\n",
    "        #     final_window = array[-final_window_size:]\n",
    "        #     sequences.append(torch.tensor(final_window))\n",
    "        #     if save_labels:\n",
    "        #         labels.append(attack_type)\n",
    "\n",
    "        del array\n",
    "        del t\n",
    "\n",
    "    del grouped_size\n",
    "    del sorted_order\n",
    "    del df\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    if save_labels:\n",
    "        with h5py.File(\"out_veremi/veremi-mixall-20-10.h5\", \"a\") as hf:\n",
    "            ds_name = f\"{file}_labels\"\n",
    "            if ds_name in hf.keys():\n",
    "                del hf[ds_name]\n",
    "            hf.create_dataset(ds_name, data=labels, compression=\"gzip\")\n",
    "        del labels\n",
    "        \n",
    "    with h5py.File(\"out_veremi/veremi-mixall-20-10.h5\", \"a\") as hf:\n",
    "        ds_name = file\n",
    "        if ds_name in hf.keys():\n",
    "            del hf[ds_name]\n",
    "        hf.create_dataset(file, data=sequences, compression=\"gzip\")\n",
    "    del sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09c84a-9394-41bc-a418-b29304f12a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
